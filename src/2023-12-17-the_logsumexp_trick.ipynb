{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4bdf732c-2a12-4e8a-8ffd-c497bd47d397",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---\n",
    "date: 2023-12-17 12:00:00-0800\n",
    "layout: post\n",
    "redirect_from:\n",
    "  - /blog/2023/logsumexp_trick/\n",
    "title: The LogSumExp trick\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8bf6a87-47a5-4507-9893-2145da40e8b7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "no_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e626646-8f1a-4a88-8e36-1ec4d7b6fd98",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c603b-f7db-4fce-8f12-301497db9cad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The [softmax function](https://en.wikipedia.org/wiki/Softmax_function) $\\sigma$ is used to transform a vector in $\\mathbb{R}^n$ to a probability vector in a monotonicity-preserving way.\n",
    "Specifically, if $x_i \\leq x_j$, then $\\sigma(x)_i \\leq \\sigma(x)_j$.\n",
    "\n",
    "The softmax is typically parametrized by a \"temperature\" parameter $T$ to yield $\\sigma_T(x) \\equiv \\sigma(x / T)$ which\n",
    "* shifts more probability mass to the largest component of $x$ as the temperature decays to zero and\n",
    "* distributes the mass more evenly among the components of $x$ as the temperature grows.\n",
    "\n",
    "More details regarding the temperature can be found in [a previous blog post](https://parsiad.ca/blog/2022/softmax_sensitivity_to_temperature/).\n",
    "\n",
    "Algebraically, the softmax is defined as\n",
    "\n",
    "$$\n",
    "\\sigma(x)_i \\equiv \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}.\n",
    "$$\n",
    "\n",
    "This quantity is clearly continuous on $\\mathbb{R}^n$ and hence finite there.\n",
    "However, in the presence of floating point computation, computing this quantity naively can result in blow-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c2dd18e-cf97-4448-b5db-28b270b291a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117792/4003806838.py:1: RuntimeWarning: overflow encountered in exp\n",
      "  exp_x = np.exp(x)\n",
      "/tmp/ipykernel_117792/4003806838.py:2: RuntimeWarning: invalid value encountered in divide\n",
      "  exp_x / exp_x.sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([768, 1024.])\n",
    "exp_x = np.exp(x)\n",
    "exp_x / exp_x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11180b0e-84ab-4a99-a3f0-7a67ffce3254",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The *LogSumExp trick* is a clever way of reformulating this computation so that it is robust to floating point error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e9e95-97c4-49e2-8824-749231d0b942",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## The LogSumExp trick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e1b1b2-a51b-43c8-90df-ca6c4b03dd78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "First, let $\\bar{x} = \\max_i x_i$ and note that\n",
    "\n",
    "$$\n",
    "\\sigma(x)_{i}=\\frac{\\exp(x_{i}-\\bar{x})}{\\sum_{j}\\exp(x_{j}-\\bar{x})}.\n",
    "$$\n",
    "\n",
    "Taking logarithms,\n",
    "\n",
    "$$\n",
    "\\log(\\sigma(x)_{i})=x_{i}-\\bar{x}-\\log\\biggl(\\sum_{j}\\exp(x_{j}-\\bar{x})\\biggr).\n",
    "$$\n",
    "\n",
    "Exponentiating,\n",
    "\n",
    "$$\n",
    "\\sigma(x)_{i}=\\exp\\biggr(x_{i}-\\bar{x}-\\log\\biggl(\\sum_{j}\\exp(x_{j}-\\bar{x})\\biggr)\\biggr).\n",
    "$$\n",
    "\n",
    "In particular, note that $x_j - \\bar{x}$ is, by construction, nonpositive and hence has a value less than one when exponentiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47b61f7b-c92b-4ee5-be97-8edbaa15dfe3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(x: np.ndarray) -> np.ndarray:\n",
    "    x_max = x.max(axis=-1, keepdims=True)\n",
    "    delta = x - x_max\n",
    "    lse = np.log(np.exp(delta).sum(axis=-1, keepdims=True))\n",
    "    return np.exp(delta - lse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c93a3d6-7949-41b8-a4b8-a139734b7427",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.61626106e-112, 1.00000000e+000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([768, 1024.])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "706cbe98-2d3f-4400-9460-fc88b09f31a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "no_cell"
    ]
   },
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(scipy.special.softmax(x), softmax(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
